{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\nfrom tensorflow.keras.models import Model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:23.706705Z","iopub.execute_input":"2023-04-30T21:26:23.708005Z","iopub.status.idle":"2023-04-30T21:26:33.714399Z","shell.execute_reply.started":"2023-04-30T21:26:23.707927Z","shell.execute_reply":"2023-04-30T21:26:33.712997Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_path =\"/kaggle/input/duckchick/train\"\ntest_path =\"/kaggle/input/duckchick/test\"\nval_path =\"/kaggle/input/duckchick/val\"\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-30T21:26:33.716893Z","iopub.execute_input":"2023-04-30T21:26:33.717748Z","iopub.status.idle":"2023-04-30T21:26:33.723645Z","shell.execute_reply.started":"2023-04-30T21:26:33.717694Z","shell.execute_reply":"2023-04-30T21:26:33.722537Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"x_train=[]\n\nfor folder in os.listdir(train_path):\n    sub_path=train_path+\"/\"+folder\n    for img in os.listdir(sub_path):\n        image_path=sub_path+\"/\"+img\n        img_arr=cv2.imread(image_path)\n        img_arr=cv2.resize(img_arr,(224,224))\n        x_train.append(img_arr)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:33.725013Z","iopub.execute_input":"2023-04-30T21:26:33.725860Z","iopub.status.idle":"2023-04-30T21:26:34.908480Z","shell.execute_reply.started":"2023-04-30T21:26:33.725813Z","shell.execute_reply":"2023-04-30T21:26:34.907241Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"x_test=[]\n\nfor folder in os.listdir(test_path):\n    sub_path=test_path+\"/\"+folder\n    for img in os.listdir(sub_path):\n        image_path=sub_path+\"/\"+img\n        img_arr=cv2.imread(image_path)\n        img_arr=cv2.resize(img_arr,(224,224))\n        x_test.append(img_arr)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:34.911229Z","iopub.execute_input":"2023-04-30T21:26:34.911801Z","iopub.status.idle":"2023-04-30T21:26:35.149244Z","shell.execute_reply.started":"2023-04-30T21:26:34.911757Z","shell.execute_reply":"2023-04-30T21:26:35.147864Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"x_val=[]\n\nfor folder in os.listdir(val_path):\n    sub_path=val_path+\"/\"+folder\n    for img in os.listdir(sub_path):\n        image_path=sub_path+\"/\"+img\n        img_arr=cv2.imread(image_path)\n        img_arr=cv2.resize(img_arr,(224,224))\n        x_val.append(img_arr)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:35.150796Z","iopub.execute_input":"2023-04-30T21:26:35.152765Z","iopub.status.idle":"2023-04-30T21:26:35.386817Z","shell.execute_reply.started":"2023-04-30T21:26:35.152688Z","shell.execute_reply":"2023-04-30T21:26:35.385392Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_x=np.array(x_train)\ntest_x=np.array(x_test)\nval_x=np.array(x_val)\ntrain_x=train_x/255.0\ntest_x=test_x/255.0\nval_x=val_x/255.0\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:35.388634Z","iopub.execute_input":"2023-04-30T21:26:35.389167Z","iopub.status.idle":"2023-04-30T21:26:35.594557Z","shell.execute_reply.started":"2023-04-30T21:26:35.389115Z","shell.execute_reply":"2023-04-30T21:26:35.592836Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255)\ntest_datagen = ImageDataGenerator(rescale = 1./255)\nval_datagen = ImageDataGenerator(rescale = 1./255)\ntraining_set = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'sparse')\ntest_set = test_datagen.flow_from_directory(test_path,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'sparse')\nval_set = val_datagen.flow_from_directory(val_path,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'sparse')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:35.596099Z","iopub.execute_input":"2023-04-30T21:26:35.596544Z","iopub.status.idle":"2023-04-30T21:26:35.913982Z","shell.execute_reply.started":"2023-04-30T21:26:35.596494Z","shell.execute_reply":"2023-04-30T21:26:35.912784Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 200 images belonging to 2 classes.\nFound 40 images belonging to 2 classes.\nFound 40 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_y=training_set.classes\ntest_y=test_set.classes\nval_y=val_set.classes\nprint(training_set.class_indices)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:35.918392Z","iopub.execute_input":"2023-04-30T21:26:35.919559Z","iopub.status.idle":"2023-04-30T21:26:35.925400Z","shell.execute_reply.started":"2023-04-30T21:26:35.919501Z","shell.execute_reply":"2023-04-30T21:26:35.924118Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'chicken': 0, 'duck': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg = VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:35.926488Z","iopub.execute_input":"2023-04-30T21:26:35.927043Z","iopub.status.idle":"2023-04-30T21:26:37.423692Z","shell.execute_reply.started":"2023-04-30T21:26:35.927006Z","shell.execute_reply":"2023-04-30T21:26:37.422290Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in vgg.layers:\n    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.427191Z","iopub.execute_input":"2023-04-30T21:26:37.427619Z","iopub.status.idle":"2023-04-30T21:26:37.435151Z","shell.execute_reply.started":"2023-04-30T21:26:37.427575Z","shell.execute_reply":"2023-04-30T21:26:37.433503Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(vgg.output)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.437034Z","iopub.execute_input":"2023-04-30T21:26:37.438944Z","iopub.status.idle":"2023-04-30T21:26:37.455345Z","shell.execute_reply.started":"2023-04-30T21:26:37.438880Z","shell.execute_reply":"2023-04-30T21:26:37.453912Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(2, activation='softmax')(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.457170Z","iopub.execute_input":"2023-04-30T21:26:37.457755Z","iopub.status.idle":"2023-04-30T21:26:37.483541Z","shell.execute_reply.started":"2023-04-30T21:26:37.457699Z","shell.execute_reply":"2023-04-30T21:26:37.482234Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=vgg.input, outputs=prediction)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.484947Z","iopub.execute_input":"2023-04-30T21:26:37.485340Z","iopub.status.idle":"2023-04-30T21:26:37.564386Z","shell.execute_reply.started":"2023-04-30T21:26:37.485302Z","shell.execute_reply":"2023-04-30T21:26:37.562823Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 2)                 50178     \n                                                                 \n=================================================================\nTotal params: 20,074,562\nTrainable params: 50,178\nNon-trainable params: 20,024,384\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n  loss='sparse_categorical_crossentropy',\n  optimizer=\"adam\",\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.566353Z","iopub.execute_input":"2023-04-30T21:26:37.566877Z","iopub.status.idle":"2023-04-30T21:26:37.593250Z","shell.execute_reply.started":"2023-04-30T21:26:37.566824Z","shell.execute_reply":"2023-04-30T21:26:37.592142Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n#Early stopping to avoid overfitting of model","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.594723Z","iopub.execute_input":"2023-04-30T21:26:37.595717Z","iopub.status.idle":"2023-04-30T21:26:37.602336Z","shell.execute_reply.started":"2023-04-30T21:26:37.595674Z","shell.execute_reply":"2023-04-30T21:26:37.600723Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_x,\n  train_y,\n  validation_data=(val_x,val_y),\n  epochs=50,\n  callbacks=[early_stop],\n  batch_size=32,shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:26:37.604660Z","iopub.execute_input":"2023-04-30T21:26:37.605194Z","iopub.status.idle":"2023-04-30T21:42:47.596370Z","shell.execute_reply.started":"2023-04-30T21:26:37.605138Z","shell.execute_reply":"2023-04-30T21:42:47.595338Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/50\n7/7 [==============================] - 77s 11s/step - loss: 1.1050 - accuracy: 0.5650 - val_loss: 0.5617 - val_accuracy: 0.7250\nEpoch 2/50\n7/7 [==============================] - 75s 11s/step - loss: 0.3874 - accuracy: 0.8250 - val_loss: 0.7568 - val_accuracy: 0.6750\nEpoch 3/50\n7/7 [==============================] - 74s 11s/step - loss: 0.1824 - accuracy: 0.9300 - val_loss: 0.7484 - val_accuracy: 0.6750\nEpoch 4/50\n7/7 [==============================] - 74s 11s/step - loss: 0.1551 - accuracy: 0.9350 - val_loss: 0.7319 - val_accuracy: 0.7000\nEpoch 5/50\n7/7 [==============================] - 75s 11s/step - loss: 0.1278 - accuracy: 0.9400 - val_loss: 0.5219 - val_accuracy: 0.7750\nEpoch 6/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0502 - accuracy: 0.9950 - val_loss: 0.4792 - val_accuracy: 0.7750\nEpoch 7/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0332 - accuracy: 0.9950 - val_loss: 0.4326 - val_accuracy: 0.7500\nEpoch 8/50\n7/7 [==============================] - 75s 11s/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.7250\nEpoch 9/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.7500\nEpoch 10/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.7500\nEpoch 11/50\n7/7 [==============================] - 75s 11s/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.7500\nEpoch 12/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.7500\nEpoch 13/50\n7/7 [==============================] - 74s 11s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.7250\nEpoch 13: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\ny_pred=model.predict(test_x)\ny_pred=np.argmax(y_pred,axis=1)\n#get classification report\nprint(classification_report(y_pred,test_y))\n#get confusion matrix\nprint(confusion_matrix(y_pred,test_y))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-30T21:42:47.598185Z","iopub.execute_input":"2023-04-30T21:42:47.599186Z","iopub.status.idle":"2023-04-30T21:43:00.891716Z","shell.execute_reply.started":"2023-04-30T21:42:47.599143Z","shell.execute_reply":"2023-04-30T21:43:00.890187Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 13s 2s/step\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90        20\n           1       0.90      0.90      0.90        20\n\n    accuracy                           0.90        40\n   macro avg       0.90      0.90      0.90        40\nweighted avg       0.90      0.90      0.90        40\n\n[[18  2]\n [ 2 18]]\n","output_type":"stream"}]}]}